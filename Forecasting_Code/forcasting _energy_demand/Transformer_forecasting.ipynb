{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation, refer: https://cienciadedatos.net/documentos/py29-forecasting-electricity-power-demand-python\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from astral.sun import sun\n",
    "# from astral import LocationInfo\n",
    "from skforecast.datasets import fetch_dataset\n",
    "\n",
    "# Plots\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook use \"Demand\" and \"Temperature\" 2 features for prediction.\n",
    "- We DO NOT rescale/normalize based on training dataset\n",
    "- The model is transformer take in to (batch_zie, sequence, feat=2) as input and output predicts (batch_zie, sequence, feat=2)\n",
    "- We use \"sequence\" length of data to predict \"one\" data point after the sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vic_electricity\n",
      "---------------\n",
      "Half-hourly electricity demand for Victoria, Australia\n",
      "O'Hara-Wild M, Hyndman R, Wang E, Godahewa R (2022).tsibbledata: Diverse\n",
      "Datasets for 'tsibble'. https://tsibbledata.tidyverts.org/,\n",
      "https://github.com/tidyverts/tsibbledata/.\n",
      "https://tsibbledata.tidyverts.org/reference/vic_elec.html\n",
      "Shape of the dataset: (52608, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52608 entries, 0 to 52607\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Time         52608 non-null  object \n",
      " 1   Demand       52608 non-null  float64\n",
      " 2   Temperature  52608 non-null  float64\n",
      " 3   Date         52608 non-null  object \n",
      " 4   Holiday      52608 non-null  bool   \n",
      "dtypes: bool(1), float64(2), object(2)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data = fetch_dataset(name='vic_electricity', raw=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Demand</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Date</th>\n",
       "      <th>Holiday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-12-31 13:00:00</th>\n",
       "      <td>4382.825174</td>\n",
       "      <td>21.40</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-31 13:30:00</th>\n",
       "      <td>4263.365526</td>\n",
       "      <td>21.05</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-31 14:00:00</th>\n",
       "      <td>4048.966046</td>\n",
       "      <td>20.70</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-31 14:30:00</th>\n",
       "      <td>3877.563330</td>\n",
       "      <td>20.55</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Demand  Temperature        Date  Holiday\n",
       "Time                                                              \n",
       "2011-12-31 13:00:00  4382.825174        21.40  2012-01-01     True\n",
       "2011-12-31 13:30:00  4263.365526        21.05  2012-01-01     True\n",
       "2011-12-31 14:00:00  4048.966046        20.70  2012-01-01     True\n",
       "2011-12-31 14:30:00  3877.563330        20.55  2012-01-01     True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data preparation\n",
    "# ==============================================================================\n",
    "data = data.copy()\n",
    "data['Time'] = pd.to_datetime(data['Time'], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "data = data.set_index('Time') # use time as index\n",
    "data = data.asfreq('30min')\n",
    "data = data.sort_index() # sort by time order\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Demand</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-12-31 14:00:00</th>\n",
       "      <td>4323.095350</td>\n",
       "      <td>21.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-31 15:00:00</th>\n",
       "      <td>3963.264688</td>\n",
       "      <td>20.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-31 16:00:00</th>\n",
       "      <td>3950.913495</td>\n",
       "      <td>20.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-31 17:00:00</th>\n",
       "      <td>3627.860675</td>\n",
       "      <td>19.850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Demand  Temperature\n",
       "Time                                         \n",
       "2011-12-31 14:00:00  4323.095350       21.225\n",
       "2011-12-31 15:00:00  3963.264688       20.625\n",
       "2011-12-31 16:00:00  3950.913495       20.325\n",
       "2011-12-31 17:00:00  3627.860675       19.850"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregating in 1H intervals\n",
    "# ==============================================================================\n",
    "# The Date column is eliminated so that it does not generate an error when aggregating.\n",
    "\n",
    "# also, in this version we drop \"Holiday\"\n",
    "data = data.drop(columns=\"Date\")\n",
    "data = data.drop(columns=\"Holiday\")\n",
    "data = (\n",
    "    data\n",
    "    .resample(rule=\"h\", closed=\"left\", label=\"right\")\n",
    "    .agg({\n",
    "        \"Demand\": \"mean\",\n",
    "        \"Temperature\": \"mean\",\n",
    "        # \"Holiday\": \"mean\",\n",
    "    })\n",
    ")\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Demand</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-31 09:00:00</th>\n",
       "      <td>4069.625550</td>\n",
       "      <td>21.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 10:00:00</th>\n",
       "      <td>3909.230704</td>\n",
       "      <td>20.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 11:00:00</th>\n",
       "      <td>3900.600901</td>\n",
       "      <td>19.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 12:00:00</th>\n",
       "      <td>3758.236494</td>\n",
       "      <td>18.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 13:00:00</th>\n",
       "      <td>3785.650720</td>\n",
       "      <td>17.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Demand  Temperature\n",
       "Time                                         \n",
       "2014-12-31 09:00:00  4069.625550        21.60\n",
       "2014-12-31 10:00:00  3909.230704        20.30\n",
       "2014-12-31 11:00:00  3900.600901        19.65\n",
       "2014-12-31 12:00:00  3758.236494        18.10\n",
       "2014-12-31 13:00:00  3785.650720        17.20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:01:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:02:00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:03:00</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:04:00</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:05:00</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:06:00</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:07:00</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:08:00</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "2000-01-01 00:00:00  0\n",
       "2000-01-01 00:01:00  1\n",
       "2000-01-01 00:02:00  2\n",
       "2000-01-01 00:03:00  3\n",
       "2000-01-01 00:04:00  4\n",
       "2000-01-01 00:05:00  5\n",
       "2000-01-01 00:06:00  6\n",
       "2000-01-01 00:07:00  7\n",
       "2000-01-01 00:08:00  8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pd.date_range('1/1/2000', periods=9, freq='min')\n",
    "series = pd.Series(range(9), index=index)\n",
    "df = series.to_frame()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates      : 2011-12-31 14:00:00 --- 2013-12-31 23:00:00  (n=17554)\n",
      "Validation dates : 2014-01-01 00:00:00 --- 2014-11-30 23:00:00  (n=8016)\n",
      "Test dates       : 2014-12-01 00:00:00 --- 2014-12-31 13:00:00  (n=734)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train-val-test set\n",
    "# Note that \"loc\" function includes both the start and the stop are included\n",
    "end_train = '2013-12-31 23:59:00'\n",
    "start_val = '2014-01-01 00:00:00'\n",
    "end_validation = '2014-11-30 23:59:00'\n",
    "start_test = '2014-12-01 00:00:00'\n",
    "\n",
    "\n",
    "data_train = data.loc[: end_train, :].copy()\n",
    "data_val   = data.loc[start_val:end_validation, :].copy()\n",
    "data_test  = data.loc[start_test: , :].copy()\n",
    "\n",
    "print(f\"Train dates      : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\")\n",
    "print(f\"Validation dates : {data_val.index.min()} --- {data_val.index.max()}  (n={len(data_val)})\")\n",
    "print(f\"Test dates       : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data frame based on training data\n",
    "- You need to normalize the test data using the parameters of the training data.\n",
    "\n",
    "- refer to https://www.reddit.com/r/econometrics/comments/1547hl5/how_to_deal_with_normalization_in_time_series/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Normalize based on training data for all datasets\n",
    "\n",
    "# # refer: https://stackoverflow.com/questions/26414913/normalize-columns-of-a-dataframe\n",
    "\n",
    "# data_train_scaled = (data_train-data_train.mean())/data_train.std()\n",
    "# data_val_scaled = (data_val-data_train.mean())/data_train.std()\n",
    "# data_test_scaled = (data_test-data_train.mean())/data_train.std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare sequence dataloader for training\n",
    " - refer to https://github.com/jeffheaton/app_deep_learning/blob/06ea8bdb9cb18151d3ada51e1fa580690a8245fe//t81_558_class_10_3_transformer_timeseries.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chwen\\AppData\\Local\\Temp\\ipykernel_28032\\2886008425.py:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  return torch.tensor(x, dtype=torch.float32).view(-1, seq_size, feat_dim), torch.tensor(y, dtype=torch.float32).view(-1, feat_dim)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# Sequence Data Preparation- use seq_size # of data to predict one data (\"window\" variable) afterward (\"after_window\" variable)\n",
    "SEQUENCE_SIZE = 10\n",
    "FEAT_DIM = 2 # pick \"Demand\", \"Temperature\"--> 2 features\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "def to_sequences(seq_size, obs):\n",
    "    x = []\n",
    "    y = []\n",
    "    obs_np = obs.to_numpy()\n",
    "    feat_dim = obs_np.shape[1]\n",
    "    for i in range(len(obs_np) - seq_size):\n",
    "        window = obs_np[i:(i + seq_size),:]\n",
    "        after_window = obs_np[i + seq_size,:]\n",
    "        x.append(window)\n",
    "        y.append(after_window)\n",
    "    return torch.tensor(x, dtype=torch.float32).view(-1, seq_size, feat_dim), torch.tensor(y, dtype=torch.float32).view(-1, feat_dim)\n",
    "\n",
    "# x_train, y_train = to_sequences(SEQUENCE_SIZE, data_train_scaled)\n",
    "# x_val, y_val = to_sequences(SEQUENCE_SIZE, data_val_scaled)\n",
    "# x_test, y_test = to_sequences(SEQUENCE_SIZE, data_test_scaled)\n",
    "x_train, y_train = to_sequences(SEQUENCE_SIZE, data_train)\n",
    "x_val, y_val = to_sequences(SEQUENCE_SIZE, data_val)\n",
    "x_test, y_test = to_sequences(SEQUENCE_SIZE, data_test)\n",
    "\n",
    "# Setup data loaders for batch\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Transformer Model for Training\n",
    "- refer to https://github.com/jeffheaton/app_deep_learning/blob/06ea8bdb9cb18151d3ada51e1fa580690a8245fe//t81_558_class_10_3_transformer_timeseries.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSimple tutorial about position encoding are:\\n# refer to https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/\\n# refer to https://discuss.pytorch.org/t/transformer-example-position-encoding-function-works-only-for-even-d-model/100986/2\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positional Encoding for Transformer (only works for even number of feature dimension)\n",
    "# so best practice is to first map your row data into even number of feature dim using nn.linear, and then apply (transformer + position enc) from there\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "'''\n",
    "Simple tutorial about position encoding are:\n",
    "# refer to https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/\n",
    "# refer to https://discuss.pytorch.org/t/transformer-example-position-encoding-function-works-only-for-even-d-model/100986/2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chwen\\anaconda3\\envs\\forecast_env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# Model definition using Transformer\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim=2, d_model=64, nhead=4, num_layers=2, dropout=0.2, pred_feat_dim=2):\n",
    "        '''\n",
    "        input_dim: its your time sequence data with selected number of feature used (we picked \"Demand\", \"Temperature\", \"Holiday\" 3 features)\n",
    "        '''\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Linear(input_dim, d_model) # as mention, first use linear layer to map raw data into even number of feature dim (aka, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.decoder = nn.Linear(d_model, pred_feat_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.decoder(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = TransformerModel(input_dim=FEAT_DIM, pred_feat_dim=FEAT_DIM).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some trainning helper function:\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chwen\\anaconda3\\envs\\forecast_env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "c:\\Users\\chwen\\anaconda3\\envs\\forecast_env\\lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 11332094.7499\n",
      "Epoch 1/10, Validation Loss: 9408950.3453\n",
      "Epoch 2/10, Training Loss: 11330953.3023\n",
      "Epoch 2/10, Validation Loss: 9408950.0608\n",
      "Epoch 3/10, Training Loss: 11330570.1482\n",
      "Epoch 3/10, Validation Loss: 9408949.3048\n",
      "Epoch 4/10, Training Loss: 11330381.2558\n",
      "Epoch 4/10, Validation Loss: 9408948.9227\n",
      "Epoch 5/10, Training Loss: 11330262.9415\n",
      "Epoch 5/10, Validation Loss: 9408948.3243\n",
      "Epoch 6/10, Training Loss: 11330185.9507\n",
      "Epoch 6/10, Validation Loss: 9408947.8651\n",
      "Epoch 7/10, Training Loss: 11330130.0887\n",
      "Epoch 7/10, Validation Loss: 9408947.2833\n",
      "Epoch 8/10, Training Loss: 11330088.7207\n",
      "Epoch 8/10, Validation Loss: 9408946.8104\n",
      "Epoch 9/10, Training Loss: 11330056.0728\n",
      "Epoch 9/10, Validation Loss: 9408946.2624\n",
      "Epoch 10/10, Training Loss: 11330030.9820\n",
      "Epoch 10/10, Validation Loss: 9408945.7724\n"
     ]
    }
   ],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "# writer = SummaryWriter('./tensorboard/data_2feat/lr1e-3')\n",
    "\n",
    "# Train the model\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "epochs = 10 #5000\n",
    "early_stop_count = 0\n",
    "min_val_loss = float('inf')\n",
    "record = {'train_loss': AverageMeter('train_loss', ':.4f'),\n",
    "          'val_loss': AverageMeter('val_loss',':.4f')}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        x_batch, y_batch = batch\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "        record['train_loss'].update(loss.detach().item(), y_batch.size(0))\n",
    "    \n",
    "    \n",
    "    # end of epoch do\n",
    "    # writer.add_scalar('train_loss', record['train_loss'].avg, epoch)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {record['train_loss'].avg:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x_batch, y_batch = batch\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(x_batch)\n",
    "            val_loss = criterion(outputs, y_batch)\n",
    "            val_losses.append(loss.item())\n",
    "            record['val_loss'].update(val_loss.detach().item(), y_batch.size(0))\n",
    "        \n",
    "        # writer.add_scalar('val_loss', record['val_loss'].avg, epoch)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {record['val_loss'].avg:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    # if val_loss < min_val_loss:\n",
    "    #     min_val_loss = val_loss\n",
    "    #     early_stop_count = 0\n",
    "    # else:\n",
    "    #     early_stop_count += 1\n",
    "\n",
    "    # if early_stop_count >= 5:\n",
    "    #     print(\"Early stopping!\")\n",
    "    #     break\n",
    "    # print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reza_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
